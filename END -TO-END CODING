# ================================
# üìå 1. IMPORT LIBRARIES
# ================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


# ================================
# üìå 2. CREATE SAMPLE DATASET
# (If you don't have Kaggle dataset)
# ================================

data = {
    "cgpa": [8.5, 7.2, 6.0, 9.1, 5.5, 7.8, 8.9, 6.5, 7.0, 9.5,
             5.8, 6.9, 8.2, 7.4, 6.2, 8.7, 9.0, 5.9, 7.6, 8.0],
    
    "internships": [2,1,0,3,0,1,2,0,1,3,
                    0,1,2,1,0,2,3,0,1,2],
    
    "projects": [3,2,1,4,1,2,3,1,2,4,
                 1,2,3,2,1,3,4,1,2,3],
    
    "communication": [8,7,6,9,5,7,8,6,7,9,
                      5,6,8,7,6,8,9,5,7,8],
    
    "status": [1,1,0,1,0,1,1,0,1,1,
               0,1,1,1,0,1,1,0,1,1]
}

df = pd.DataFrame(data)

print("Dataset Preview:")
print(df.head())


# ================================
# üìå 3. DATA VISUALIZATION
# ================================

sns.countplot(x="status", data=df)
plt.title("Placement Distribution")
plt.show()


# ================================
# üìå 4. SPLIT DATA
# ================================

X = df[["cgpa", "internships", "projects", "communication"]]
y = df["status"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


# ================================
# üìå 5. TRAIN LOGISTIC REGRESSION
# ================================

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)

lr_pred = lr_model.predict(X_test)

print("\n--- Logistic Regression ---")
print("Accuracy:", accuracy_score(y_test, lr_pred))
print(confusion_matrix(y_test, lr_pred))
print(classification_report(y_test, lr_pred))


# ================================
# üìå 6. TRAIN RANDOM FOREST
# ================================

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

rf_pred = rf_model.predict(X_test)

print("\n--- Random Forest ---")
print("Accuracy:", accuracy_score(y_test, rf_pred))
print(confusion_matrix(y_test, rf_pred))
print(classification_report(y_test, rf_pred))


# ================================
# üìå 7. SAVE BEST MODEL
# ================================

# Save Random Forest (better usually)
pickle.dump(rf_model, open("placement_model.pkl", "wb"))

print("\nModel saved as placement_model.pkl")


# ================================
# üìå 8. TEST MANUAL PREDICTION
# ================================

sample_student = np.array([[8.2, 2, 3, 8]])  # cgpa, internships, projects, communication
prediction = rf_model.predict(sample_student)

if prediction[0] == 1:
    print("Prediction: High Chance of Placement ‚úÖ")
else:
    print("Prediction: Low Chance of Placement ‚ùå")
